{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probe Training Tutorial\n",
    "\n",
    "We use transformer lens to load models, embeddings etc. \n",
    "We use regex and nltk to get tokens matching natural language english words which start with particular letters.\n",
    "We train linear probes on a balanced dataset, and track binary classification quality. \n",
    "\n",
    "For now, this is almost all \"under the hood\".\n",
    "\n",
    "To do:\n",
    "- Find optimal hyper-parameters. \n",
    "- Explore internal probes. \n",
    "- Understand the directions in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/gpt-j-6B into HookedTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjbloom\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/github_repositories/alphabetical_probe/tutorials/wandb/run-20231107_234724-rpegz6h9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jbloom/letter_presence_probes/runs/rpegz6h9' target=\"_blank\">ethereal-galaxy-120</a></strong> to <a href='https://wandb.ai/jbloom/letter_presence_probes' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jbloom/letter_presence_probes' target=\"_blank\">https://wandb.ai/jbloom/letter_presence_probes</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jbloom/letter_presence_probes/runs/rpegz6h9' target=\"_blank\">https://wandb.ai/jbloom/letter_presence_probes/runs/rpegz6h9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 4 | Loss: 0.3835 | Precision: 0.7500 | Recall: 1.0000: 100%|██████████| 771/771 [00:01<00:00, 673.92it/s]\n",
      "Epoch 2 / 4 | Loss: 0.2803 | Precision: 0.9286 | Recall: 0.9286: 100%|██████████| 771/771 [00:00<00:00, 883.25it/s]\n",
      "Epoch 3 / 4 | Loss: 0.2091 | Precision: 1.0000 | Recall: 1.0000: 100%|██████████| 771/771 [00:00<00:00, 882.35it/s]\n",
      "Epoch 4 / 4 | Loss: 0.1323 | Precision: 1.0000 | Recall: 1.0000: 100%|██████████| 771/771 [00:00<00:00, 891.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval_metrics/accuracy</td><td>▁▅▆█</td></tr><tr><td>eval_metrics/f1</td><td>▁▄▆█</td></tr><tr><td>eval_metrics/loss</td><td>█▄▂▁</td></tr><tr><td>eval_metrics/precision</td><td>▁▄▅█</td></tr><tr><td>eval_metrics/recall</td><td>▁▁▁▁</td></tr><tr><td>metrics/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_metrics/loss</td><td>██▇▇▆▅▅▅▅▄▃▄▄▃▃▂▃▃▃▂▃▃▃▂▂▁▂▁▁▁▁▁▁▁▁▁▁▂▁▁</td></tr><tr><td>training_metrics/precision</td><td>▂▁▃▃████▆▇▆█▆▅▆█▄▆▆███▅█▇██████████▆█▆██</td></tr><tr><td>training_metrics/recall</td><td>██████▂████▃██████████▂███████▁█████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval_metrics/accuracy</td><td>98.45917</td></tr><tr><td>eval_metrics/f1</td><td>0.81481</td></tr><tr><td>eval_metrics/loss</td><td>0.15438</td></tr><tr><td>eval_metrics/precision</td><td>68.75</td></tr><tr><td>eval_metrics/recall</td><td>100.0</td></tr><tr><td>metrics/learning_rate</td><td>0.001</td></tr><tr><td>training_metrics/loss</td><td>0.1323</td></tr><tr><td>training_metrics/precision</td><td>1.0</td></tr><tr><td>training_metrics/recall</td><td>1.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ethereal-galaxy-120</strong> at: <a href='https://wandb.ai/jbloom/letter_presence_probes/runs/rpegz6h9' target=\"_blank\">https://wandb.ai/jbloom/letter_presence_probes/runs/rpegz6h9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231107_234724-rpegz6h9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/github_repositories/alphabetical_probe/tutorials/wandb/run-20231107_234738-dquty53w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jbloom/letter_presence_probes/runs/dquty53w' target=\"_blank\">fancy-violet-121</a></strong> to <a href='https://wandb.ai/jbloom/letter_presence_probes' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jbloom/letter_presence_probes' target=\"_blank\">https://wandb.ai/jbloom/letter_presence_probes</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jbloom/letter_presence_probes/runs/dquty53w' target=\"_blank\">https://wandb.ai/jbloom/letter_presence_probes/runs/dquty53w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 4 | Loss: 0.3261 | Precision: 1.0000 | Recall: 1.0000: 100%|██████████| 771/771 [00:00<00:00, 886.96it/s]\n",
      "Epoch 2 / 4 | Loss: 0.2718 | Precision: 1.0000 | Recall: 1.0000: 100%|██████████| 771/771 [00:00<00:00, 881.48it/s]\n",
      "Epoch 3 / 4 | Loss: 0.1556 | Precision: 1.0000 | Recall: 1.0000: 100%|██████████| 771/771 [00:00<00:00, 881.98it/s]\n",
      "Epoch 4 / 4 | Loss: 0.1337 | Precision: 1.0000 | Recall: 1.0000: 100%|██████████| 771/771 [00:00<00:00, 878.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval_metrics/accuracy</td><td>▁▃▅█</td></tr><tr><td>eval_metrics/f1</td><td>▁▃▅█</td></tr><tr><td>eval_metrics/loss</td><td>█▄▂▁</td></tr><tr><td>eval_metrics/precision</td><td>▁▃▄█</td></tr><tr><td>eval_metrics/recall</td><td>▁▁▁▁</td></tr><tr><td>metrics/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_metrics/loss</td><td>██▇▇▆▆▅▅▅▄▄▄▄▃▄▄▃▃▃▃▂▂▂▂▃▂▃▁▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>training_metrics/precision</td><td>▁▁▁▆███▇███▆▆█▇▅█▇███████▇▇███▇█████████</td></tr><tr><td>training_metrics/recall</td><td>████▁███████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval_metrics/accuracy</td><td>98.38213</td></tr><tr><td>eval_metrics/f1</td><td>0.76923</td></tr><tr><td>eval_metrics/loss</td><td>0.13647</td></tr><tr><td>eval_metrics/precision</td><td>62.5</td></tr><tr><td>eval_metrics/recall</td><td>100.0</td></tr><tr><td>metrics/learning_rate</td><td>0.001</td></tr><tr><td>training_metrics/loss</td><td>0.13373</td></tr><tr><td>training_metrics/precision</td><td>1.0</td></tr><tr><td>training_metrics/recall</td><td>1.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fancy-violet-121</strong> at: <a href='https://wandb.ai/jbloom/letter_presence_probes/runs/dquty53w' target=\"_blank\">https://wandb.ai/jbloom/letter_presence_probes/runs/dquty53w</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231107_234738-dquty53w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/github_repositories/alphabetical_probe/tutorials/wandb/run-20231107_234753-418e6jed</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jbloom/letter_presence_probes/runs/418e6jed' target=\"_blank\">stoic-aardvark-122</a></strong> to <a href='https://wandb.ai/jbloom/letter_presence_probes' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jbloom/letter_presence_probes' target=\"_blank\">https://wandb.ai/jbloom/letter_presence_probes</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jbloom/letter_presence_probes/runs/418e6jed' target=\"_blank\">https://wandb.ai/jbloom/letter_presence_probes/runs/418e6jed</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 4 | Loss: 0.3781 | Precision: 1.0000 | Recall: 1.0000: 100%|██████████| 771/771 [00:00<00:00, 864.00it/s]\n",
      "Epoch 2 / 4 | Loss: 0.2011 | Precision: 1.0000 | Recall: 1.0000: 100%|██████████| 771/771 [00:00<00:00, 865.84it/s]\n",
      "Epoch 3 / 4 | Loss: 0.1833 | Precision: 1.0000 | Recall: 1.0000: 100%|██████████| 771/771 [00:00<00:00, 897.24it/s]\n",
      "Epoch 4 / 4 | Loss: 0.1082 | Precision: 0.9500 | Recall: 1.0000: 100%|██████████| 771/771 [00:00<00:00, 884.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval_metrics/accuracy</td><td>▁▄▇█</td></tr><tr><td>eval_metrics/f1</td><td>▁▄▆█</td></tr><tr><td>eval_metrics/loss</td><td>█▄▂▁</td></tr><tr><td>eval_metrics/precision</td><td>▁▃▆█</td></tr><tr><td>eval_metrics/recall</td><td>▁▁▁▁</td></tr><tr><td>metrics/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_metrics/loss</td><td>██▇▇▆▆▅▄▄▄▄▄▃▃▄▃▃▃▃▃▃▂▂▂▂▃▂▂▂▂▁▁▂▁▂▁▁▁▁▁</td></tr><tr><td>training_metrics/precision</td><td>█▅█▅▁██▅███▅█████▅███▅███▆██████████████</td></tr><tr><td>training_metrics/recall</td><td>▁███████████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval_metrics/accuracy</td><td>99.30663</td></tr><tr><td>eval_metrics/f1</td><td>0.85246</td></tr><tr><td>eval_metrics/loss</td><td>0.11289</td></tr><tr><td>eval_metrics/precision</td><td>74.28571</td></tr><tr><td>eval_metrics/recall</td><td>100.0</td></tr><tr><td>metrics/learning_rate</td><td>0.001</td></tr><tr><td>training_metrics/loss</td><td>0.10821</td></tr><tr><td>training_metrics/precision</td><td>0.95</td></tr><tr><td>training_metrics/recall</td><td>1.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stoic-aardvark-122</strong> at: <a href='https://wandb.ai/jbloom/letter_presence_probes/runs/418e6jed' target=\"_blank\">https://wandb.ai/jbloom/letter_presence_probes/runs/418e6jed</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231107_234753-418e6jed/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/github_repositories/alphabetical_probe/tutorials/wandb/run-20231107_234809-u3g0apo7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jbloom/letter_presence_probes/runs/u3g0apo7' target=\"_blank\">aggregate_artifact_logging</a></strong> to <a href='https://wandb.ai/jbloom/letter_presence_probes' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jbloom/letter_presence_probes' target=\"_blank\">https://wandb.ai/jbloom/letter_presence_probes</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jbloom/letter_presence_probes/runs/u3g0apo7' target=\"_blank\">https://wandb.ai/jbloom/letter_presence_probes/runs/u3g0apo7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">aggregate_artifact_logging</strong> at: <a href='https://wandb.ai/jbloom/letter_presence_probes/runs/u3g0apo7' target=\"_blank\">https://wandb.ai/jbloom/letter_presence_probes/runs/u3g0apo7</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231107_234809-u3g0apo7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from transformer_lens.HookedTransformer import HookedTransformer\n",
    "from transformer_lens.loading_from_pretrained import OFFICIAL_MODEL_NAMES\n",
    "\n",
    "OFFICIAL_MODEL_NAMES[1:10]\n",
    "model = HookedTransformer.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
    "\n",
    "from src.probe_training import all_probe_training_runner\n",
    "\n",
    "vocab = model.tokenizer.get_vocab()\n",
    "probe_weights_tensor = all_probe_training_runner(\n",
    "    embeddings=model.W_E.detach(),\n",
    "    vocab=vocab,\n",
    "    alphabet=\"CAR\",\n",
    "    criteria_mode=\"starts\",\n",
    "    probe_type=\"linear\",\n",
    "    num_epochs=4,\n",
    "    batch_size=32,\n",
    "    learning_rate=0.005,\n",
    "    train_test_split=0.95,\n",
    "    rebalance=True,\n",
    "    use_wandb=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Visualize Predictions, we can do something like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0102, -0.0008, -0.0030,  ..., -0.0065,  0.0065,  0.0147],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "torch.Size([4096])\n",
      "tensor([False, False, False, False, False, False, False, False,  True, False,\n",
      "         True,  True,  True, False, False,  True], device='cuda:0')\n",
      "tensor(0.3125, device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "-0.010202172212302685",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/root/github_repositories/alphabetical_probe/tutorials/probe_training.ipynb Cell 4\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22566173744149227d/root/github_repositories/alphabetical_probe/tutorials/probe_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m fig\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22566173744149227d/root/github_repositories/alphabetical_probe/tutorials/probe_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=64'>65</a>\u001b[0m reverse_vocab \u001b[39m=\u001b[39m {v: k \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m vocab\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22566173744149227d/root/github_repositories/alphabetical_probe/tutorials/probe_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m words \u001b[39m=\u001b[39m [reverse_vocab[i\u001b[39m.\u001b[39;49mitem()]\u001b[39m.\u001b[39;49mstrip(\u001b[39m\"\u001b[39;49m\u001b[39mĠ\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m batch[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39;49m]]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22566173744149227d/root/github_repositories/alphabetical_probe/tutorials/probe_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=66'>67</a>\u001b[0m plot_batch_predictions(words, batch[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m], probe_weights_tensor[\u001b[39m\"\u001b[39m\u001b[39mA\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[1;32m/root/github_repositories/alphabetical_probe/tutorials/probe_training.ipynb Cell 4\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22566173744149227d/root/github_repositories/alphabetical_probe/tutorials/probe_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m fig\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22566173744149227d/root/github_repositories/alphabetical_probe/tutorials/probe_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=64'>65</a>\u001b[0m reverse_vocab \u001b[39m=\u001b[39m {v: k \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m vocab\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22566173744149227d/root/github_repositories/alphabetical_probe/tutorials/probe_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m words \u001b[39m=\u001b[39m [reverse_vocab[i\u001b[39m.\u001b[39;49mitem()]\u001b[39m.\u001b[39mstrip(\u001b[39m\"\u001b[39m\u001b[39mĠ\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m batch[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22566173744149227d/root/github_repositories/alphabetical_probe/tutorials/probe_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=66'>67</a>\u001b[0m plot_batch_predictions(words, batch[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m], probe_weights_tensor[\u001b[39m\"\u001b[39m\u001b[39mA\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[0;31mKeyError\u001b[0m: -0.010202172212302685"
     ]
    }
   ],
   "source": [
    "from src.dataset import get_letter_dataset\n",
    "\n",
    "train_loader, test_loader = get_letter_dataset(\n",
    "    criterion=\"starts\",\n",
    "    target=\"A\",\n",
    "    embeddings=model.W_E,\n",
    "    vocab=vocab,\n",
    "    batch_size=16,\n",
    "    rebalance=True,\n",
    ")\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(batch[0][0])\n",
    "    print(batch[0][1].shape)\n",
    "    print(batch[1])\n",
    "    # get proportions of positive and negative labels\n",
    "    print(sum(batch[1]) / len(batch[1]))\n",
    "    break\n",
    "\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def plot_batch_predictions(words, embeddings, probe):\n",
    "    predictions = probe(embeddings).squeeze()\n",
    "    predictions = predictions.squeeze()\n",
    "\n",
    "    # make a dataframe\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"words\": words,\n",
    "            \"predictions\": predictions.cpu().detach().numpy(),\n",
    "            \"labels\": batch[1].cpu().detach().numpy(),\n",
    "        }\n",
    "    )\n",
    "    # convert labels to bool\n",
    "    df[\"labels\"] = df[\"labels\"].astype(bool)\n",
    "    # sort by predictions\n",
    "    df = df.sort_values(by=[\"predictions\"], ascending=True)\n",
    "\n",
    "    fig = px.bar(\n",
    "        df,\n",
    "        y=\"words\",\n",
    "        x=\"predictions\",\n",
    "        color=\"labels\",\n",
    "        title=\"Probe weights for letter A\",\n",
    "        labels={\n",
    "            \"x\": \"Word\",\n",
    "            \"y\": \"Probe Logit\",\n",
    "            \"labels\": \"Starts with A\",\n",
    "        },\n",
    "        text_auto=\"0.2f\",\n",
    "        text=\"words\",\n",
    "        height=800,\n",
    "        # width=1200,\n",
    "        template=\"plotly_white\",\n",
    "        category_orders={\"index\": df.index[::-1]},\n",
    "    )\n",
    "    # update the hover template to make the word much larger\n",
    "    fig.update_traces(hovertemplate=\"<b>%{y}</b><br><br>%{x}\")\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "reverse_vocab = {v: k for k, v in vocab.items()}\n",
    "words = [reverse_vocab[i.item()].strip(\"Ġ\") for i in batch[0][0]]\n",
    "plot_batch_predictions(words, batch[0][1], probe_weights_tensor[\"A\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alphabetical_probe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
